"""
–£–º–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –≤ —Å—Ç–∏–ª–µ Rsync
"""
import os
import hashlib
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger("FileSync")

class FileSync:
    def __init__(self, config):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        
        Args:
            config: –æ–±—ä–µ–∫—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        self.config = config
        self.sync_dir = config.data_dir / "sync"
        self.sync_dir.mkdir(exist_ok=True)
        
        # –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        self.sync_state_file = self.sync_dir / "sync_state.json"
        self.sync_state = self._load_sync_state()
        
        # –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 4KB)
        self.block_size = 4096
        
        logger.info("–°–∏—Å—Ç–µ–º–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def _load_sync_state(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        if self.sync_state_file.exists():
            try:
                with open(self.sync_state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def _save_sync_state(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        with open(self.sync_state_file, 'w', encoding='utf-8') as f:
            json.dump(self.sync_state, f, indent=2, ensure_ascii=False)
    
    def calculate_file_hash(self, file_path: Path, algorithm: str = 'sha256') -> str:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Ñ–∞–π–ª–∞
        
        Args:
            file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            algorithm: –∞–ª–≥–æ—Ä–∏—Ç–º —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            str: —Ö–µ—à —Ñ–∞–π–ª–∞
        """
        hash_func = hashlib.new(algorithm)
        
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(self.block_size), b""):
                hash_func.update(chunk)
        
        return hash_func.hexdigest()
    
    def sync_files(self, source_dir: str, target_dir: str, 
                   delete_missing: bool = False, 
                   dry_run: bool = False) -> Dict:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–≤—É—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        
        Args:
            source_dir: –∏—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            target_dir: —Ü–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            delete_missing: —É–¥–∞–ª—è—Ç—å –ª–∏ —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
            dry_run: —Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (–±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π)
            
        Returns:
            Dict: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        """
        source_path = Path(source_dir)
        target_path = Path(target_dir)
        
        if not source_path.exists():
            return {'error': f'–ò—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {source_dir}'}
        
        if not target_path.exists():
            if not dry_run:
                target_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {target_dir}")
        
        stats = {
            'total_files': 0,
            'copied': 0,
            'skipped': 0,
            'updated': 0,
            'deleted': 0,
            'errors': 0,
            'start_time': datetime.now().isoformat()
        }
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for root, dirs, files in os.walk(source_path):
            # –°–æ–∑–¥–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ —Ü–µ–ª–µ–≤–æ–π
            rel_path = Path(root).relative_to(source_path)
            target_subdir = target_path / rel_path
            
            if not dry_run:
                target_subdir.mkdir(parents=True, exist_ok=True)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
            for file in files:
                stats['total_files'] += 1
                
                source_file = Path(root) / file
                target_file = target_subdir / file
                
                try:
                    result = self._sync_single_file(source_file, target_file, dry_run)
                    
                    if result == 'copied':
                        stats['copied'] += 1
                    elif result == 'skipped':
                        stats['skipped'] += 1
                    elif result == 'updated':
                        stats['updated'] += 1
                
                except Exception as e:
                    stats['errors'] += 1
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ {source_file}: {e}")
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if delete_missing:
            deleted = self._delete_extra_files(source_path, target_path, dry_run)
            stats['deleted'] = deleted
        
        stats['end_time'] = datetime.now().isoformat()
        
        if not dry_run:
            self._save_sync_state()
        
        return stats
    
    def _sync_single_file(self, source_file: Path, target_file: Path, dry_run: bool) -> str:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        
        Returns:
            str: —Ä–µ–∑—É–ª—å—Ç–∞—Ç - 'copied', 'skipped', 'updated'
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ü–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª
        if not target_file.exists():
            if not dry_run:
                shutil.copy2(source_file, target_file)
                logger.info(f"–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {source_file} -> {target_file}")
            return 'copied'
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã
        source_hash = self.calculate_file_hash(source_file)
        target_hash = self.calculate_file_hash(target_file)
        
        # –§–∞–π–ª—ã –∏–¥–µ–Ω—Ç–∏—á–Ω—ã - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if source_hash == target_hash:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π): {source_file}")
            return 'skipped'
        
        # –§–∞–π–ª—ã —Ä–∞–∑–Ω—ã–µ - –æ–±–Ω–æ–≤–ª—è–µ–º
        if not dry_run:
            shutil.copy2(source_file, target_file)
            logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω: {source_file}")
        
        return 'updated'
    
    def _delete_extra_files(self, source_path: Path, target_path: Path, dry_run: bool) -> int:
        """
        –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ —Ü–µ–ª–∏, –Ω–æ –Ω–µ—Ç –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
        
        Returns:
            int: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        deleted_count = 0
        
        for root, dirs, files in os.walk(target_path):
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø—É—Ç—å –≤ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            rel_path = Path(root).relative_to(target_path)
            source_subdir = source_path / rel_path
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
            for file in files:
                target_file = Path(root) / file
                source_file = source_subdir / file
                
                if not source_file.exists():
                    if not dry_run:
                        try:
                            target_file.unlink()
                            logger.info(f"–£–¥–∞–ª–µ–Ω (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ): {target_file}")
                            deleted_count += 1
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {target_file}: {e}")
                    else:
                        logger.info(f"[DRY RUN] –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω: {target_file}")
                        deleted_count += 1
        
        return deleted_count
    
    def create_snapshot(self, directory: str, snapshot_name: str = None) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–Ω–∏–º–æ–∫ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        
        Args:
            directory: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–Ω–∏–º–∫–∞
            snapshot_name: –∏–º—è —Å–Ω–∏–º–∫–∞ (–µ—Å–ª–∏ None - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            
        Returns:
            Dict: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–Ω–∏–º–∫–µ
        """
        dir_path = Path(directory)
        
        if not dir_path.exists():
            return {'error': f'–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {directory}'}
        
        if snapshot_name is None:
            snapshot_name = f"snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        snapshot_data = {
            'name': snapshot_name,
            'directory': str(dir_path),
            'created_at': datetime.now().isoformat(),
            'files': {}
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                file_path = Path(root) / file
                rel_path = file_path.relative_to(dir_path)
                
                try:
                    file_hash = self.calculate_file_hash(file_path)
                    stat = file_path.stat()
                    
                    snapshot_data['files'][str(rel_path)] = {
                        'hash': file_hash,
                        'size': stat.st_size,
                        'modified': stat.st_mtime,
                        'created': stat.st_ctime
                    }
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–Ω–∏–º–æ–∫
        snapshots_dir = self.sync_dir / "snapshots"
        snapshots_dir.mkdir(exist_ok=True)
        
        snapshot_file = snapshots_dir / f"{snapshot_name}.json"
        with open(snapshot_file, 'w', encoding='utf-8') as f:
            json.dump(snapshot_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"–°–æ–∑–¥–∞–Ω —Å–Ω–∏–º–æ–∫: {snapshot_name} ({len(snapshot_data['files'])} —Ñ–∞–π–ª–æ–≤)")
        
        return {
            'snapshot_name': snapshot_name,
            'file_count': len(snapshot_data['files']),
            'snapshot_file': str(snapshot_file)
        }
    
    def list_snapshots(self) -> List[Dict]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–Ω–∏–º–∫–æ–≤
        
        Returns:
            List[Dict]: —Å–ø–∏—Å–æ–∫ —Å–Ω–∏–º–∫–æ–≤
        """
        snapshots_dir = self.sync_dir / "snapshots"
        
        if not snapshots_dir.exists():
            return []
        
        snapshots = []
        
        for snapshot_file in snapshots_dir.glob("*.json"):
            try:
                with open(snapshot_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                snapshots.append({
                    'name': data.get('name', snapshot_file.stem),
                    'created_at': data.get('created_at', ''),
                    'directory': data.get('directory', ''),
                    'file_count': len(data.get('files', {})),
                    'file': str(snapshot_file)
                })
            except:
                snapshots.append({
                    'name': snapshot_file.stem,
                    'created_at': '',
                    'directory': '',
                    'file_count': 0,
                    'file': str(snapshot_file)
                })
        
        return sorted(snapshots, key=lambda x: x['created_at'], reverse=True)
    
    def compare_with_snapshot(self, directory: str, snapshot_name: str) -> Dict:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ —Å–Ω–∏–º–∫–æ–º
        
        Returns:
            Dict: —Ä–∞–∑–ª–∏—á–∏—è
        """
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–Ω–∏–º–æ–∫ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        current_state = {}
        dir_path = Path(directory)
        
        if not dir_path.exists():
            return {'error': f'–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {directory}'}
        
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                file_path = Path(root) / file
                rel_path = file_path.relative_to(dir_path)
                
                try:
                    file_hash = self.calculate_file_hash(file_path)
                    current_state[str(rel_path)] = file_hash
                except:
                    pass
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–Ω–∏–º–æ–∫
        snapshot_file = self.sync_dir / "snapshots" / f"{snapshot_name}.json"
        
        if not snapshot_file.exists():
            return {'error': f'–°–Ω–∏–º–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω: {snapshot_name}'}
        
        try:
            with open(snapshot_file, 'r', encoding='utf-8') as f:
                snapshot_data = json.load(f)
        except:
            return {'error': f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–Ω–∏–º–∫–∞: {snapshot_name}'}
        
        snapshot_state = {path: info['hash'] for path, info in snapshot_data.get('files', {}).items()}
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º
        differences = {
            'added': [],
            'removed': [],
            'modified': [],
            'unchanged': []
        }
        
        all_files = set(current_state.keys()) | set(snapshot_state.keys())
        
        for file in all_files:
            current_hash = current_state.get(file)
            snapshot_hash = snapshot_state.get(file)
            
            if current_hash is None:
                differences['removed'].append(file)
            elif snapshot_hash is None:
                differences['added'].append(file)
            elif current_hash != snapshot_hash:
                differences['modified'].append(file)
            else:
                differences['unchanged'].append(file)
        
        return {
            'snapshot': snapshot_name,
            'directory': directory,
            'compared_at': datetime.now().isoformat(),
            'differences': differences,
            'summary': {
                'total_files': len(all_files),
                'added': len(differences['added']),
                'removed': len(differences['removed']),
                'modified': len(differences['modified']),
                'unchanged': len(differences['unchanged'])
            }
        }

# –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–±–µ—Ä—Ç–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ (–î–û–ë–ê–í–õ–ï–ù–û)
def sync_files_sync(config, source_dir: str, target_dir: str, **kwargs):
    sync = FileSync(config)
    return sync.sync_files(source_dir, target_dir, **kwargs)

def create_snapshot_sync(config, directory: str, snapshot_name: str = None):
    sync = FileSync(config)
    return sync.create_snapshot(directory, snapshot_name)

def list_snapshots_sync(config):
    sync = FileSync(config)
    return sync.list_snapshots()

def compare_with_snapshot_sync(config, directory: str, snapshot_name: str):
    sync = FileSync(config)
    return sync.compare_with_snapshot(directory, snapshot_name)

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏")
    
    class TestConfig:
        data_dir = Path("test_data")
        data_dir.mkdir(exist_ok=True)
    
    config = TestConfig()
    sync = FileSync(config)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    source_dir = config.data_dir / "source"
    target_dir = config.data_dir / "target"
    
    source_dir.mkdir(exist_ok=True)
    target_dir.mkdir(exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    test_file1 = source_dir / "file1.txt"
    test_file2 = source_dir / "file2.txt"
    
    with open(test_file1, 'w') as f:
        f.write("–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª 1")
    
    with open(test_file2, 'w') as f:
        f.write("–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª 2")
    
    print(f"–°–æ–∑–¥–∞–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ {source_dir}")
    
    # –¢–µ—Å—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
    stats = sync.sync_files(str(source_dir), str(target_dir), dry_run=True)
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (dry run):")
    print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']}")
    print(f"  –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {stats['copied']}")
    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
    
    # –¢–µ—Å—Ç —Å–Ω–∏–º–∫–∞
    snapshot = sync.create_snapshot(str(source_dir), "test_snapshot")
    print(f"\nüì∏ –°–æ–∑–¥–∞–Ω —Å–Ω–∏–º–æ–∫: {snapshot['snapshot_name']}")
    print(f"  –§–∞–π–ª–æ–≤: {snapshot['file_count']}")
    
    # –°–ø–∏—Å–æ–∫ —Å–Ω–∏–º–∫–æ–≤
    snapshots = sync.list_snapshots()
    print(f"\nüìÅ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–Ω–∏–º–∫–∏: {len(snapshots)}")
    
    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")